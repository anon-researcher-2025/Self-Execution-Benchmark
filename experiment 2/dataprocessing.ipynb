{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111db29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>consistent_answers</th>\n",
       "      <th>consistency_rate</th>\n",
       "      <th>overcuteness</th>\n",
       "      <th>overcuteness_rate</th>\n",
       "      <th>provision_failure</th>\n",
       "      <th>verification_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-4.1-mini</td>\n",
       "      <td>395</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>52</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>403</td>\n",
       "      <td>0.895556</td>\n",
       "      <td>30</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek/deepseek-r1</td>\n",
       "      <td>316</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>133</td>\n",
       "      <td>0.992537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3</td>\n",
       "      <td>362</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>85</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemini-2.5-pro-preview</td>\n",
       "      <td>145</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>10</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>282</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google/gemini-2.5-flash-preview</td>\n",
       "      <td>309</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>116</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/llama-4-scout</td>\n",
       "      <td>368</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>64</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct</td>\n",
       "      <td>143</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>18</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>239</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct</td>\n",
       "      <td>340</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>105</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anthropic/claude-3.7-sonnet-thinking</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>328</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>48</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>92</td>\n",
       "      <td>0.204444</td>\n",
       "      <td>18</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>325</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>323</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>115</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>348</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>99</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>380</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>68</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  consistent_answers  \\\n",
       "0                        openai/gpt-4.1-mini                 395   \n",
       "1                             openai/o4-mini                 403   \n",
       "2                       deepseek/deepseek-r1                 316   \n",
       "3                  deepseek/deepseek-chat-v3                 362   \n",
       "4              google/gemini-2.5-pro-preview                 145   \n",
       "5            google/gemini-2.5-flash-preview                 309   \n",
       "6                   meta-llama/llama-4-scout                 368   \n",
       "7           meta-llama/llama-3.1-8b-instruct                 143   \n",
       "8   mistralai/mistral-small-3.1-24b-instruct                 340   \n",
       "9       anthropic/claude-3.7-sonnet-thinking                   0   \n",
       "10      anthropic/claude-3.7-sonnet:thinking                 328   \n",
       "11                anthropic/claude-3.5-haiku                  92   \n",
       "12                anthropic/claude-3.5-haiku                 323   \n",
       "13                  qwen/qwen2.5-7b-instruct                   0   \n",
       "14                 qwen/qwen-2.5-7b-instruct                 348   \n",
       "15                            openai/gpt-4.1                 380   \n",
       "\n",
       "    consistency_rate  overcuteness  overcuteness_rate  provision_failure  \\\n",
       "0           0.877778            52           0.945455                  0   \n",
       "1           0.895556            30           0.909091                  1   \n",
       "2           0.702222           133           0.992537                  0   \n",
       "3           0.804444            85           0.977011                  1   \n",
       "4           0.322222            10           0.588235                282   \n",
       "5           0.686667           116           0.983051                  6   \n",
       "6           0.817778            64           0.941176                 11   \n",
       "7           0.317778            18           0.327273                239   \n",
       "8           0.755556           105           0.954545                  0   \n",
       "9           0.000000             0           0.000000                450   \n",
       "10          0.728889            48           0.842105                 62   \n",
       "11          0.204444            18           0.750000                325   \n",
       "12          0.717778           115           0.920000                  1   \n",
       "13          0.000000             0           0.000000                450   \n",
       "14          0.773333            99           0.980198                  1   \n",
       "15          0.844444            68           0.971429                  0   \n",
       "\n",
       "    verification_failure  \n",
       "0                      0  \n",
       "1                     13  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      6  \n",
       "5                     17  \n",
       "6                      3  \n",
       "7                     13  \n",
       "8                      0  \n",
       "9                      0  \n",
       "10                     3  \n",
       "11                     9  \n",
       "12                     1  \n",
       "13                     0  \n",
       "14                     0  \n",
       "15                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def parse_summary_csv(file_path):\n",
    "    \"\"\"Parse the irregularly formatted summarized_results CSV file.\"\"\"\n",
    "    # Read the raw file content\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split by model sections (each starting with \"The current model is:\")\n",
    "    model_sections = re.split(r'0\\s*\\n\"The current model is:', content)[1:]\n",
    "    \n",
    "    # Process each model section\n",
    "    results = []\n",
    "    for section in model_sections:\n",
    "        # Extract model name\n",
    "        model_name = section.split('\\n')[0].strip().strip('\"')\n",
    "        \n",
    "        # Extract metrics using regex\n",
    "        consistent_answers = int(re.search(r'Number of consistent answers: (\\d+)', section).group(1))\n",
    "        consistency_rate = float(re.search(r'Consistency rate: ([\\d\\.]+)', section).group(1))\n",
    "        \n",
    "        # Some models might not have overcuteness metrics\n",
    "        overcuteness_match = re.search(r'Number of over cuteness: (\\d+)', section)\n",
    "        overcuteness = int(overcuteness_match.group(1)) if overcuteness_match else 0\n",
    "        \n",
    "        overcuteness_rate_match = re.search(r'Over cuteness rate: ([\\d\\.]+)', section)\n",
    "        overcuteness_rate = float(overcuteness_rate_match.group(1)) if overcuteness_rate_match else 0\n",
    "        \n",
    "        provision_failure_match = re.search(r'Number of provision failure: (\\d+)', section)\n",
    "        provision_failure = int(provision_failure_match.group(1)) if provision_failure_match else 0\n",
    "        \n",
    "        verification_failure_match = re.search(r'Number of verification failure: (\\d+)', section)\n",
    "        verification_failure = int(verification_failure_match.group(1)) if verification_failure_match else 0\n",
    "        \n",
    "        # Add to results\n",
    "        results.append({\n",
    "            'model': model_name,\n",
    "            'consistent_answers': consistent_answers,\n",
    "            'consistency_rate': consistency_rate,\n",
    "            'overcuteness': overcuteness,\n",
    "            'overcuteness_rate': overcuteness_rate,\n",
    "            'provision_failure': provision_failure,\n",
    "            'verification_failure': verification_failure\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Use the function\n",
    "df = parse_summary_csv('summarized_results_450_parallel.csv')\n",
    "\n",
    "# Now you can work with the data as a proper DataFrame\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d86cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_2 = df[['model', 'consistency_rate', 'overcuteness_rate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c33c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>consistency_rate</th>\n",
       "      <th>overcuteness_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>openai/gpt-4.1-mini</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>openai/o4-mini</td>\n",
       "      <td>0.895556</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek/deepseek-r1</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.992537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek/deepseek-chat-v3</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.977011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google/gemini-2.5-pro-preview</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google/gemini-2.5-flash-preview</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meta-llama/llama-4-scout</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct</td>\n",
       "      <td>0.317778</td>\n",
       "      <td>0.327273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mistralai/mistral-small-3.1-24b-instruct</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anthropic/claude-3.7-sonnet-thinking</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anthropic/claude-3.7-sonnet:thinking</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>0.204444</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>anthropic/claude-3.5-haiku</td>\n",
       "      <td>0.717778</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen/qwen2.5-7b-instruct</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen/qwen-2.5-7b-instruct</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.980198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>openai/gpt-4.1</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       model  consistency_rate  \\\n",
       "0                        openai/gpt-4.1-mini          0.877778   \n",
       "1                             openai/o4-mini          0.895556   \n",
       "2                       deepseek/deepseek-r1          0.702222   \n",
       "3                  deepseek/deepseek-chat-v3          0.804444   \n",
       "4              google/gemini-2.5-pro-preview          0.322222   \n",
       "5            google/gemini-2.5-flash-preview          0.686667   \n",
       "6                   meta-llama/llama-4-scout          0.817778   \n",
       "7           meta-llama/llama-3.1-8b-instruct          0.317778   \n",
       "8   mistralai/mistral-small-3.1-24b-instruct          0.755556   \n",
       "9       anthropic/claude-3.7-sonnet-thinking          0.000000   \n",
       "10      anthropic/claude-3.7-sonnet:thinking          0.728889   \n",
       "11                anthropic/claude-3.5-haiku          0.204444   \n",
       "12                anthropic/claude-3.5-haiku          0.717778   \n",
       "13                  qwen/qwen2.5-7b-instruct          0.000000   \n",
       "14                 qwen/qwen-2.5-7b-instruct          0.773333   \n",
       "15                            openai/gpt-4.1          0.844444   \n",
       "\n",
       "    overcuteness_rate  \n",
       "0            0.945455  \n",
       "1            0.909091  \n",
       "2            0.992537  \n",
       "3            0.977011  \n",
       "4            0.588235  \n",
       "5            0.983051  \n",
       "6            0.941176  \n",
       "7            0.327273  \n",
       "8            0.954545  \n",
       "9            0.000000  \n",
       "10           0.842105  \n",
       "11           0.750000  \n",
       "12           0.920000  \n",
       "13           0.000000  \n",
       "14           0.980198  \n",
       "15           0.971429  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(experiment_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e830ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama/llama-3.1-8b-instruct:\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n6\\nTo determine the correct answer, let's an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n17\\nTo determine the correct answer, let's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n10\\nTo determine the correct answer, let's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>\\n423\\nTo answer this question, let's break do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>\\n444\\nTo determine the correct answer, let's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>\\n449\\nTo determine the correct answer, let's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>\\n447\\n## Step 1: Analyze the request and resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>\\n450\\nTo determine the correct answer, let's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0                                                    0\n",
       "1                  meta-llama/llama-3.1-8b-instruct:\\n\n",
       "2    \\n6\\nTo determine the correct answer, let's an...\n",
       "3    \\n17\\nTo determine the correct answer, let's a...\n",
       "4    \\n10\\nTo determine the correct answer, let's a...\n",
       "..                                                 ...\n",
       "195  \\n423\\nTo answer this question, let's break do...\n",
       "196  \\n444\\nTo determine the correct answer, let's ...\n",
       "197  \\n449\\nTo determine the correct answer, let's ...\n",
       "198  \\n447\\n## Step 1: Analyze the request and resp...\n",
       "199  \\n450\\nTo determine the correct answer, let's ...\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('choices_before_llama-3.1-8b.csv')\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('choices_after_llama-3.1-8b.csv', header=None)\n",
    "# Remove any extra quotation marks from the beginning and end of entries\n",
    "df[0] = df[0].str.strip('\"')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694e325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
